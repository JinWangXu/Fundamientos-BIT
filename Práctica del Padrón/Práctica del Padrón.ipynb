{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e5384d6",
   "metadata": {},
   "source": [
    "# Práctica del Padrón"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e753c76",
   "metadata": {},
   "source": [
    "## Creación de tablas en Hive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d742d35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "//Crea la base de datos\n",
    "create database datos_padron\n",
    "\n",
    "//Creación de tablas almacenados en csv o parquet en HDFS\n",
    "create table padron_txt(\n",
    "COD_DISTRITO string,\n",
    "DESC_DISTRITO string,\n",
    "COD_DIST_BARRIO string,\n",
    "DESC_BARRIO string,\n",
    "COD_BARRIO string,\n",
    "COD_DIST_SECCION string,\n",
    "COD_SECCION string,\n",
    "COD_EDAD_INT string,\n",
    "EspanolesHombres string,\n",
    "EspanolesMujeres string,\n",
    "ExtranjerosHombres string,\n",
    "ExtranjerosMujeres string)\n",
    "ROW FORMAT DELIMITED\n",
    "FIELDS TERMINATED BY '\\;'\n",
    "STORED AS TEXTFILE;\n",
    "\n",
    "\n",
    "create table padron_txt2(\n",
    "COD_DISTRITO int,\n",
    "DESC_DISTRITO string,\n",
    "COD_DIST_BARRIO int,\n",
    "DESC_BARRIO string,\n",
    "COD_BARRIO int,\n",
    "COD_DIST_SECCION int,\n",
    "COD_SECCION int,\n",
    "COD_EDAD_INT int,\n",
    "EspanolesHombres int,\n",
    "EspanolesMujeres int,\n",
    "ExtranjerosHombres int,\n",
    "ExtranjerosMujeres int)\n",
    "ROW FORMAT SERDE 'org.apache.hadoop.hive.serde2.OpenCSVSerde'\n",
    "WITH SERDEPROPERTIES (\n",
    "'separatorChar' = '\\073',\n",
    "'quoteChar' = '\"',\n",
    "'escapeChar' = '\\\\')\n",
    "STORED AS TEXTFILE\n",
    "tblproperties(\"skip.header.line.count\"=\"1\");\n",
    "\n",
    "Load data inpath '/user/cloudera/hive/Rango_Edades_Seccion_202106.csv' into table padron_txt2;\n",
    "\n",
    "\n",
    "create table padron_txt3\n",
    "STORED AS TEXTFILE\n",
    "AS SELECT COD_DISTRITO, TRIM(DESC_DISTRITO) as DESC_DISTRITO , COD_DIST_BARRIO, TRIM(DESC_BARRIO) as DESC_BARRIO, COD_BARRIO, COD_DIST_SECCION, COD_SECCION, COD_EDAD_INT,\n",
    "CASE WHEN EspanolesHombres = '' THEN 0 ELSE EspanolesHombres END AS EspanolesHombres,\n",
    "CASE WHEN EspanolesMujeres = '' THEN 0 ELSE EspanolesMujeres END AS EspanolesMujeres,\n",
    "CASE WHEN ExtranjerosHombres = '' THEN 0 ELSE ExtranjerosHombres END AS ExtranjerosHombres,\n",
    "CASE WHEN ExtranjerosMujeres = '' THEN 0 ELSE ExtranjerosMujeres END AS ExtranjerosMujeres\n",
    "FROM padron_txt2; \n",
    "\n",
    "CREATE TABLE datos_padron.padron_txt_reg (COD_DISTRITO INT,  DESC_DISTRITO STRING,\n",
    "COD_DIST_BARRIO INT, DESC_BARRIO STRING,\n",
    "COD_BARRIO INT, COD_DIST_SECCION INT,\n",
    "COD_SECCION INT, COD_EDAD_INT INT,\n",
    "EspanolesHombres INT, EspanolesMujeres INT,\n",
    "ExtranjerosHombres INT, ExtranjerosMujeres INT)\n",
    "ROW FORMAT SERDE 'org.apache.hadoop.hive.serde2.RegexSerDe'\n",
    "WITH SERDEPROPERTIES (\"input.regex\"=\"'(\\\\d+)'\\;'(.*?)\\\\s*'\\;'(\\\\d+)'\\;'(.*?)\\s*'\\;'(\\\\d+)'\\;'(\\\\d+)'\\;'(\\\\d+)'\\;'(\\\\d+)'\\;'(.*?)'\\;'(.*?)'\\;'(.*?)'\\;'(.*?)\", \"serialization.encoding\"=\"UTF-8\")\n",
    "STORED AS TEXTFILE;\n",
    "\n",
    "Load data inpath '/user/cloudera/hive/Rango_Edades_Seccion_202106.csv' into table datos_padron.padron_txt_reg;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e3cbfa",
   "metadata": {},
   "source": [
    "CTAS es una forma de crear una tabla en base al contenido de otra mediante una consulta selectiva.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d95e5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "create table padron_parquet \n",
    "STORED AS PARQUET\n",
    "as SELECT * from padron_txt;\n",
    "\n",
    "create table padron_parquet2\n",
    "STORED AS PARQUET\n",
    "as SELECT * from padron_txt2;\n",
    "\n",
    "create table padron_parquet3\n",
    "STORED AS PARQUET\n",
    "as SELECT * from padron_txt3;\n",
    "\n",
    "//Para mirar el tamaño de las tablas\n",
    "\n",
    "hdfs dfs -du -s -h /user/hive/warehouse/datos_padron.db/padron_txt\n",
    "hdfs dfs -du -s -h /user/hive/warehouse/datos_padron.db/padron_parquet\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a95209",
   "metadata": {},
   "source": [
    "### Impala\n",
    "\n",
    "Impala es otro motor SQL que, de igual forma que Hive, opera consultas sobre\n",
    "HDFS. Hive e Impala son herramientas diferentes, y cada uno ofrece unas\n",
    "características importantes:\n",
    "\n",
    "Impala fue creado para resolver los problemas de tiempo de ejecución elevadas de\n",
    "Hive, ya que opera las consultas de datos directamente en el clúster de HDFS, sin\n",
    "utilizar los Jobs con MapReduce. Sin embargo, pierde la tolerancia de fallos que\n",
    "facilitaba MapReduce, por lo que si una query falla por el sistema, es necesario\n",
    "relanzar la consulta. Como resultado, Impala suele ser hasta 20 veces más rápido\n",
    "que Hive.\n",
    "\n",
    "Normalmente, estas dos herramientas se utilizan en proyectos grandes, ya que en\n",
    "caso de realizar procesos ETL para extraer, transformar y cargar datos, buscando\n",
    "robustez sin importar el tiempo computacional, es muy conveniente utilizar Hive. Y\n",
    "luego con Impala para realizar consultas rápidas tras cargar los datos con Hive.\n",
    "\n",
    "\n",
    "⦁\tLa diferencia entre Impala y Hive es que Impala ejecuta las queries directamente en un clúster y hive en un MapReduce. Como podemos recordar, en los ejericicos de Hijve, ejecutaban un reducer por cada agrupación (sum, count, etc).\n",
    "\n",
    "⦁\tPor ello Impala es mucho más rápido de Hive o Pig\n",
    "\n",
    "⦁\tPara utilizar Impala no es necesario saber programar. Únicamente es necesario saber realizar queries.\n",
    "\n",
    "⦁\tImpala, como Hive, operan sobre los mismos datos: tablas en HDFS, y metadatos en el Metastore.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb177ebd",
   "metadata": {},
   "source": [
    "La INVALIDATE METADATAdeclaración marca los metadatos de una o todas las tablas como obsoletos. La próxima vez que el servicio Impala realiza una consulta en una tabla cuyos metadatos se invalidan, Impala vuelve a cargar los metadatos asociados antes de que continúe la consulta. Como esta es una operación muy costosa en comparación con la actualización incremental de metadatos realizada por la REFRESHdeclaración, cuando sea posible, prefiera en REFRESH lugar de INVALIDATE METADATA.\n",
    "\n",
    "INVALIDATE METADATA es necesario cuando se realizan los siguientes cambios fuera de Impala, en Hive y otros clientes de Hive, como SparkSQL:\n",
    "\n",
    "Cambios en los metadatos de las tablas existentes.\n",
    "\n",
    "Se agregan nuevas tablas e Impala las usará.\n",
    "\n",
    "Se cambian los privilegios de centinela SERVERo DATABASEnivel.\n",
    "\n",
    "Bloquea los cambios de metadatos, pero los archivos siguen siendo los mismos (reequilibrio de HDFS).\n",
    "\n",
    "Los frascos UDF cambian.\n",
    "\n",
    "Algunas tablas ya no se consultan y desea eliminar sus metadatos de las cachés del coordinador y del catálogo para reducir los requisitos de memoria.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "756f1775",
   "metadata": {},
   "outputs": [],
   "source": [
    "//HIVE\n",
    "SELECT DESC_DISTRITO, DESC_BARRIO, sum(EspanolesHombres) as TotalESPH, sum(EspanolesMujeres) as TotalESPM, sum(ExtranjerosHombres) as TotalEXH, sum(ExtranjerosMujeres) as EXM FROM padron_txt3 GROUP BY DESC_DISTRITO, DESC_BARRIO\n",
    "SELECT DESC_DISTRITO, DESC_BARRIO, sum(EspanolesHombres) as TotalESPH, sum(EspanolesMujeres) as TotalESPM, sum(ExtranjerosHombres) as TotalEXH, sum(ExtranjerosMujeres) as EXM FROM padron_parquet GROUP BY DESC_DISTRITO, DESC_BARRIO\n",
    "//IMPALA\n",
    "SELECT DESC_DISTRITO, DESC_BARRIO, sum(CAST(EspanolesHombres AS INT)) as TotalESPH, sum(CAST(EspanolesMujeres AS INT)) as TotalESPM, sum(CAST(ExtranjerosHombres AS INT)) as TotalEXH, sum(CAST(ExtranjerosMujeres AS INT)) as TotalEXM FROM padron_txt3 GROUP BY DESC_DISTRITO, DESC_BARRIO\n",
    "SELECT DESC_DISTRITO, DESC_BARRIO, sum(CAST(EspanolesHombres AS INT)) as TotalESPH, sum(CAST(EspanolesMujeres AS INT)) as TotalESPM, sum(CAST(ExtranjerosHombres AS INT)) as TotalEXH, sum(CAST(ExtranjerosMujeres AS INT)) as TotalEXM FROM padron_parquet3 GROUP BY DESC_DISTRITO, DESC_BARRIO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66373fdb",
   "metadata": {},
   "source": [
    "## Tablas particionadas\n",
    "\n",
    "En este ejemplo particionamos el COD_Distrito en COD_Barrio, por lo que tendremosdentro del warehouse de Hive en HDFS una cantidad de ficheros distribuidos por estos dos campos y hacer la búsuqeda más reducida y eficiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9064889d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "SET hive.exec.dynamic.partition.mode=nonstrict;\n",
    "SET hive.exec.max.dynamic.partitions=100000;\n",
    "SET hive.exec.max.dynamic.partitions.pernode=100000;\n",
    "\n",
    "create table padron_particionado(\n",
    "DESC_DISTRITO string,\n",
    "COD_DIST_BARRIO string,\n",
    "DESC_BARRIO string,\n",
    "COD_DIST_SECCION string,\n",
    "COD_SECCION string,\n",
    "COD_EDAD_INT string,\n",
    "EspanolesHombres string,\n",
    "EspanolesMujeres string,\n",
    "ExtranjerosHombres string,\n",
    "ExtranjerosMujeres string)\n",
    "PARTITIONED BY (COD_DISTRITO string, COD_BARRIO string)\n",
    "STORED AS PARQUET;\n",
    "\n",
    "\n",
    "INSERT OVERWRITE TABLE padron_particionado PARTITION(COD_DISTRITO, COD_BARRIO)\n",
    "SELECT DESC_DISTRITO,\n",
    "COD_DIST_BARRIO,\n",
    "DESC_BARRIO,\n",
    "COD_DIST_SECCION,\n",
    "COD_SECCION,\n",
    "COD_EDAD_INT,\n",
    "EspanolesHombres,\n",
    "EspanolesMujeres,\n",
    "ExtranjerosHombres,\n",
    "ExtranjerosMujeres,\n",
    "COD_DISTRITO,\n",
    "COD_BARRIO\n",
    "FROM padron_parquet3;\n",
    "\n",
    "//Por qué cuando creo tablas en Hive, no se me actualizan en Impala? No se supone que leen los mismos metadatos alojados en HDFS?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b14fceeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "//Parquet3\n",
    "SELECT COD_DISTRITO, \n",
    "COD_BARRIO, sum(EspanolesHombres) as TotalESPH, sum(EspanolesMujeres) as TotalESPM, \n",
    "sum(ExtranjerosHombres) as TotalEXH, sum(ExtranjerosMujeres) as EXM \n",
    "FROM padron_parquet3 WHERE COD_DISTRITO IN (1, 5, 10, 19, 6, 21)\n",
    "GROUP BY COD_DISTRITO, COD_BARRIO ;\n",
    "//Time taken: 23.303 seconds, Fetched: 35 row(s)\n",
    "\n",
    "//Particionado\n",
    "SELECT COD_DISTRITO, \n",
    "COD_BARRIO, sum(EspanolesHombres) as TotalESPH, sum(EspanolesMujeres) as TotalESPM, \n",
    "sum(ExtranjerosHombres) as TotalEXH, sum(ExtranjerosMujeres) as EXM \n",
    "FROM padron_particionado WHERE COD_DISTRITO IN (1, 5, 10, 19, 6, 21)\n",
    "GROUP BY COD_DISTRITO, COD_BARRIO ;\n",
    "//Time taken: 23.676 seconds\n",
    "\n",
    "//TextFile\n",
    "SELECT COD_DISTRITO, \n",
    "COD_BARRIO, sum(EspanolesHombres) as TotalESPH, sum(EspanolesMujeres) as TotalESPM, \n",
    "sum(ExtranjerosHombres) as TotalEXH, sum(ExtranjerosMujeres) as EXM \n",
    "FROM padron_txt3 WHERE COD_DISTRITO IN (1, 5, 10, 19, 6, 21)\n",
    "GROUP BY COD_DISTRITO, COD_BARRIO ;\n",
    "//Time taken: 23.72 seconds, Fetched: 35 row(s)\n",
    "\n",
    "//"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec85f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "//En IMPALA\n",
    "\n",
    "//Parquet3\n",
    "SELECT COD_DISTRITO, \n",
    "COD_BARRIO, sum(CAST(EspanolesHombres AS INT)) as TotalESPH, sum(CAST(EspanolesMujeres AS INT)) as TotalESPM, \n",
    "sum(CAST(ExtranjerosHombres AS INT)) as TotalEXH, sum(CAST(ExtranjerosMujeres AS INT)) as EXM \n",
    "FROM padron_parquet3 WHERE COD_DISTRITO IN ('1', '5', '10', '19', '6', '21')\n",
    "GROUP BY COD_DISTRITO, COD_BARRIO ;\n",
    "//Fetched 35 row(s) in 0.75s\n",
    "\n",
    "//Particionado\n",
    "SELECT COD_DISTRITO, \n",
    "COD_BARRIO, sum(CAST(EspanolesHombres AS INT)) as TotalESPH, sum(CAST(EspanolesMujeres AS INT)) as TotalESPM, \n",
    "sum(CAST(ExtranjerosHombres AS INT)) as TotalEXH, sum(CAST(ExtranjerosMujeres AS INT)) as EXM \n",
    "FROM padron_particionado WHERE COD_DISTRITO IN ('1', '5', '10', '19', '6', '21')\n",
    "GROUP BY COD_DISTRITO, COD_BARRIO ;\n",
    "// Fetched 35 row(s) in 0.83s\n",
    "\n",
    "\n",
    "//TextFile\n",
    "SELECT COD_DISTRITO, \n",
    "COD_BARRIO, sum(CAST(EspanolesHombres AS INT)) as TotalESPH, sum(CAST(EspanolesMujeres AS INT)) as TotalESPM, \n",
    "sum(CAST(ExtranjerosHombres AS INT)) as TotalEXH, sum(CAST(ExtranjerosMujeres AS INT)) as EXM \n",
    "FROM padron_txt3 WHERE COD_DISTRITO IN ('1', '5', '10', '19', '6', '21')\n",
    "GROUP BY COD_DISTRITO, COD_BARRIO ;\n",
    "//Fetched 35 row(s) in 3.66s\n",
    "//Es más tarde, ya que hay que leer todo el conjunto de datos, y ya luego estrcuturar las columnas.\n",
    "//En cambio en parquet únicamente lees las columnas específicas del conjunto de datos y la estructura columnar ya está hecho."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10657c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "//Prueba de rendimiento\n",
    "\n",
    "SELECT * from padron_parquet where COD_DISTRITO = 1 AND COD_BARRIO = 1;\n",
    "SELECT * from padron_particionado where COD_DISTRITO = 1 AND COD_BARRIO = 1;\n",
    "\n",
    "// Para tabla particionada\n",
    "SELECT COD_DISTRITO, COD_BARRIO, max(EspanolesHombres) as MAXESPH, min(EspanolesHombres) as MINESPH,\n",
    "avg(EspanolesHombres) as AVGESPH, count(*) as TOTAL\n",
    "FROM padron_particionado WHERE COD_DISTRITO IN (1, 5, 10, 19, 6, 21)\n",
    "GROUP BY COD_DISTRITO, COD_BARRIO;\n",
    "//Time taken: 27.471 seconds\n",
    "\n",
    "SELECT COD_DISTRITO, COD_BARRIO, max(EspanolesMujeres) as MAXESPM, min(EspanolesMujeres) as MINESPM,\n",
    "avg(EspanolesMujeres) as AVGESPM, count(*) as TOTAL\n",
    "FROM padron_particionado WHERE COD_DISTRITO IN (1, 5, 10, 19, 6, 21)\n",
    "GROUP BY COD_DISTRITO, COD_BARRIO ;\n",
    "//Time taken: 21.28 seconds\n",
    "\n",
    "SELECT COD_DISTRITO, COD_BARRIO, max(ExtranjerosHombres) as MAXEXH, min(ExtranjerosHombres) as MINEXH,\n",
    "avg(ExtranjerosHombres) as AVGEXH, count(*) as TOTAL\n",
    "FROM padron_particionado WHERE COD_DISTRITO IN (1, 5, 10, 19, 6, 21)\n",
    "GROUP BY COD_DISTRITO, COD_BARRIO ;\n",
    "\n",
    "SELECT COD_DISTRITO, COD_BARRIO, max(ExtranjerosMujeres) as MAXEXM, min(ExtranjerosMujeres) as MINEXM,\n",
    "avg(ExtranjerosMujeres) as AVGEXM, count(*) as TOTAL\n",
    "FROM padron_particionado WHERE COD_DISTRITO IN (1, 5, 10, 19, 6, 21)\n",
    "GROUP BY COD_DISTRITO, COD_BARRIO ;\n",
    "\n",
    "// Para tabla parquet\n",
    "SELECT COD_DISTRITO, COD_BARRIO, max(EspanolesHombres) as MAXESPH, min(EspanolesHombres) as MINESPH,\n",
    "avg(EspanolesHombres) as AVGESPH, count(*) as TOTAL\n",
    "FROM padron_parquet3 WHERE COD_DISTRITO IN (1, 5, 10, 19, 6, 21)\n",
    "GROUP BY COD_DISTRITO, COD_BARRIO;\n",
    "//Time taken: 22.975 seconds, Fetched: 35 row(s)\n",
    "\n",
    "SELECT COD_DISTRITO, COD_BARRIO, max(EspanolesMujeres) as MAXESPM, min(EspanolesMujeres) as MINESPM,\n",
    "avg(EspanolesMujeres) as AVGESPM, count(*) as TOTAL\n",
    "FROM padron_parquet3 WHERE COD_DISTRITO IN (1, 5, 10, 19, 6, 21)\n",
    "GROUP BY COD_DISTRITO, COD_BARRIO ;\n",
    "//Time taken: 21.717 seconds, Fetched: 35 row(s)\n",
    "\n",
    "\n",
    "SELECT COD_DISTRITO, COD_BARRIO, max(ExtranjerosHombres) as MAXEXH, min(ExtranjerosHombres) as MINEXH,\n",
    "avg(ExtranjerosHombres) as AVGEXH, count(*) as TOTAL\n",
    "FROM padron_parquet3 WHERE COD_DISTRITO IN (1, 5, 10, 19, 6, 21)\n",
    "GROUP BY COD_DISTRITO, COD_BARRIO ;\n",
    "\n",
    "SELECT COD_DISTRITO, COD_BARRIO, max(ExtranjerosMujeres) as MAXEXM, min(ExtranjerosMujeres) as MINEXM,\n",
    "avg(ExtranjerosMujeres) as AVGEXM, count(*) as TOTAL\n",
    "FROM padron_parquet3 WHERE COD_DISTRITO IN (1, 5, 10, 19, 6, 21)\n",
    "GROUP BY COD_DISTRITO, COD_BARRIO ;\n",
    "\n",
    "// Para tabla textfile\n",
    "SELECT COD_DISTRITO, COD_BARRIO, max(EspanolesHombres) as MAXESPH, min(EspanolesHombres) as MINESPH,\n",
    "avg(EspanolesHombres) as AVGESPH, count(*) as TOTAL\n",
    "FROM padron_txt3 WHERE COD_DISTRITO IN (1, 5, 10, 19, 6, 21)\n",
    "GROUP BY COD_DISTRITO, COD_BARRIO;\n",
    "//Time taken: 20.831 seconds, Fetched: 35 row(s)\n",
    "\n",
    "SELECT COD_DISTRITO, COD_BARRIO, max(EspanolesMujeres) as MAXESPM, min(EspanolesMujeres) as MINESPM,\n",
    "avg(EspanolesMujeres) as AVGESPM, count(*) as TOTAL\n",
    "FROM padron_txt3 WHERE COD_DISTRITO IN (1, 5, 10, 19, 6, 21)\n",
    "GROUP BY COD_DISTRITO, COD_BARRIO ;\n",
    "//Time taken: 32.027 seconds, Fetched: 35 row(s)\n",
    "\n",
    "SELECT COD_DISTRITO, COD_BARRIO, max(ExtranjerosHombres) as MAXEXH, min(ExtranjerosHombres) as MINEXH,\n",
    "avg(ExtranjerosHombres) as AVGEXH, count(*) as TOTAL\n",
    "FROM padron_txt3 WHERE COD_DISTRITO IN (1, 5, 10, 19, 6, 21)\n",
    "GROUP BY COD_DISTRITO, COD_BARRIO ;\n",
    "\n",
    "SELECT COD_DISTRITO, COD_BARRIO, max(ExtranjerosMujeres) as MAXEXM, min(ExtranjerosMujeres) as MINEXM,\n",
    "avg(ExtranjerosMujeres) as AVGEXM, count(*) as TOTAL\n",
    "FROM padron_txt3 WHERE COD_DISTRITO IN (1, 5, 10, 19, 6, 21)\n",
    "GROUP BY COD_DISTRITO, COD_BARRIO ;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4754e62",
   "metadata": {},
   "source": [
    "## 5 Tablas Gestionadas y no gestionadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d5d2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "create table numeros_tbl(\n",
    "col1 int,\n",
    "col2 int,\n",
    "col3 int)\n",
    "ROW FORMAT DELIMITED\n",
    "FIELDS TERMINATED BY ','\n",
    "STORED AS TEXTFILE;\n",
    "\n",
    "Load data inpath '/user/cloudera/test/datos1.txt' into table numeros.numeros_tbl;\n",
    "\n",
    "create external table numeros.numeros_tbl(\n",
    "col1 int,\n",
    "col2 int,\n",
    "col3 int)\n",
    "ROW FORMAT DELIMITED\n",
    "FIELDS TERMINATED BY ','\n",
    "STORED AS TEXTFILE\n",
    "LOCATION '/user/cloudera/test';"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c774de2d",
   "metadata": {},
   "source": [
    "En Hive cuando cargas los datos de un fichero, recoge ese fichero de HDFS y lo almacena en el warehouse de Hive.\n",
    "Cuando borramos la tabla, se borra el fichero.\n",
    "\n",
    "Sin embargo, en caso de crearlo externo, al borrarlo el fichero vuelve a estar en el directorio de HDFS que estaba anteriormente.\n",
    "\n",
    "Cuando realizamos un select de la tabla, sin haber cargado ningún dato, si lo situamos en el mismo directorio que contiene los datos del fichero, se cargan automáticamente\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e900b449",
   "metadata": {},
   "source": [
    "## 6 Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f586f98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intitializing Scala interpreter ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Spark Web UI available at http://EM2021002844.bosonit.local:4040\n",
       "SparkContext available as 'sc' (version = 3.1.1, master = local[*], app id = local-1624520846037)\n",
       "SparkSession available as 'spark'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "padron_notClean: org.apache.spark.sql.DataFrame = [COD_DISTRITO: int, DESC_DISTRITO: string ... 10 more fields]\r\n",
       "padron_df: org.apache.spark.sql.DataFrame = [COD_DISTRITO: int, DESC_DISTRITO: string ... 10 more fields]\r\n"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val padron_notClean = (spark.read.format(\"csv\")\n",
    " .option(\"header\", \"true\")\n",
    " .option(\"delimiter\", \";\")\n",
    " .option(\"inferSchema\", \"true\")\n",
    " //.enableHiveSupport()\n",
    " .load(\"Rango_Edades_Seccion_202106.csv\"))\n",
    "\n",
    "val padron_df = padron_notClean.select(col(\"COD_DISTRITO\"), \n",
    "                                   trim(col(\"DESC_DISTRITO\")).alias(\"DESC_DISTRITO\"), \n",
    "                                   col(\"COD_DIST_BARRIO\"),\n",
    "                                   trim(col(\"DESC_BARRIO\")).alias(\"DESC_BARRIO\"),\n",
    "                                   col(\"COD_BARRIO\"),\n",
    "                                   col(\"COD_DIST_SECCION\"),\n",
    "                                   col(\"COD_SECCION\"),\n",
    "                                   col(\"COD_EDAD_INT\"),\n",
    "                                   when(col(\"EspanolesHombres\").isNull, 0).otherwise(col(\"EspanolesHombres\")).alias(\"EspanolesHombres\"),\n",
    "                                   when(col(\"EspanolesMujeres\").isNull, 0).otherwise(col(\"EspanolesMujeres\")).alias(\"EspanolesMujeres\"),\n",
    "                                   when(col(\"ExtranjerosHombres\").isNull, 0).otherwise(col(\"ExtranjerosHombres\")).alias(\"ExtranjerosHombres\"),\n",
    "                                   when(col(\"ExtranjerosMujeres\").isNull, 0).otherwise(col(\"ExtranjerosMujeres\")).alias(\"ExtranjerosMujeres\")\n",
    "                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e59e962d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- COD_DISTRITO: integer (nullable = true)\n",
      " |-- DESC_DISTRITO: string (nullable = true)\n",
      " |-- COD_DIST_BARRIO: integer (nullable = true)\n",
      " |-- DESC_BARRIO: string (nullable = true)\n",
      " |-- COD_BARRIO: integer (nullable = true)\n",
      " |-- COD_DIST_SECCION: integer (nullable = true)\n",
      " |-- COD_SECCION: integer (nullable = true)\n",
      " |-- COD_EDAD_INT: integer (nullable = true)\n",
      " |-- EspanolesHombres: integer (nullable = true)\n",
      " |-- EspanolesMujeres: integer (nullable = true)\n",
      " |-- ExtranjerosHombres: integer (nullable = true)\n",
      " |-- ExtranjerosMujeres: integer (nullable = true)\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "padron_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "d621eeaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----+\n",
      "| DESC_BARRIO|rank|\n",
      "+------------+----+\n",
      "|VALDEFUENTES|   1|\n",
      "|VALDEFUENTES|   2|\n",
      "|VALDEFUENTES|   3|\n",
      "|VALDEFUENTES|   4|\n",
      "|VALDEFUENTES|   5|\n",
      "|VALDEFUENTES|   6|\n",
      "|VALDEFUENTES|   7|\n",
      "|VALDEFUENTES|   8|\n",
      "|VALDEFUENTES|   9|\n",
      "|VALDEFUENTES|  10|\n",
      "|VALDEFUENTES|  11|\n",
      "|VALDEFUENTES|  12|\n",
      "|VALDEFUENTES|  13|\n",
      "|VALDEFUENTES|  14|\n",
      "|VALDEFUENTES|  15|\n",
      "|VALDEFUENTES|  16|\n",
      "|VALDEFUENTES|  17|\n",
      "|VALDEFUENTES|  18|\n",
      "|VALDEFUENTES|  19|\n",
      "|VALDEFUENTES|  20|\n",
      "+------------+----+\n",
      "only showing top 20 rows\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT DISTINCT DESC_BARRIO, rank \n",
    " FROM ( \n",
    " SELECT DISTINCT DESC_BARRIO, row_number() \n",
    " OVER (PARTITION BY DESC_BARRIO ORDER BY DESC_BARRIO) as rank \n",
    " FROM padron\n",
    " ) t \n",
    "\"\"\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7f8575dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "//Crear vista temporal del padron\n",
    "padron_df.createOrReplaceTempView(\"padron\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b5ea0ee7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|Total_Barrios|\n",
      "+-------------+\n",
      "|          132|\n",
      "+-------------+\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "//Cuenta todos los diferentes barrios\n",
    "spark.sql(\"SELECT count(DISTINCT DESC_BARRIO) as Total_Barrios FROM padron\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f9158085",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "padron_longitud: org.apache.spark.sql.DataFrame = [COD_DISTRITO: int, DESC_DISTRITO: string ... 11 more fields]\r\n"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//Añade una columna nueva longitud que cuente la cantidad de caracteres\n",
    "val padron_longitud = padron_df.withColumn(\"longitud\", expr(\"char_length(DESC_DISTRITO)\"))\n",
    "padron_longitud.createOrReplaceTempView(\"padron_longitud\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "96c62677",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------+\n",
      "|      DESC_DISTRITO|longitud|\n",
      "+-------------------+--------+\n",
      "|         ARGANZUELA|      10|\n",
      "|FUENCARRAL-EL PARDO|      19|\n",
      "|              USERA|       5|\n",
      "|          SALAMANCA|       9|\n",
      "| PUENTE DE VALLECAS|      18|\n",
      "|  VILLA DE VALLECAS|      17|\n",
      "|           CHAMBERI|       8|\n",
      "|          VICALVARO|       9|\n",
      "|             RETIRO|       6|\n",
      "|             CENTRO|       6|\n",
      "|SAN BLAS-CANILLEJAS|      19|\n",
      "|          CHAMARTIN|       9|\n",
      "|             LATINA|       6|\n",
      "|          MORATALAZ|       9|\n",
      "|            BARAJAS|       7|\n",
      "|             TETUAN|       6|\n",
      "|      CIUDAD LINEAL|      13|\n",
      "|          HORTALEZA|       9|\n",
      "|         VILLAVERDE|      10|\n",
      "|        CARABANCHEL|      11|\n",
      "+-------------------+--------+\n",
      "only showing top 20 rows\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT DISTINCT DESC_DISTRITO, longitud FROM padron_longitud\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "baaa040d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "padron_5: org.apache.spark.sql.DataFrame = [COD_DISTRITO: int, DESC_DISTRITO: string ... 12 more fields]\r\n"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//Crear una columna que ponga un 5 para cada fila de la tabla\n",
    "val padron_5 = padron_longitud.withColumn(\"valor_5\", lit(5))\n",
    "padron_5.createOrReplaceTempView(\"padron_5\")\n",
    "padron_5.drop(\"valor_5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8cf45171",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------+\n",
      "|      DESC_DISTRITO|valor_5|\n",
      "+-------------------+-------+\n",
      "|              USERA|      5|\n",
      "|             TETUAN|      5|\n",
      "|      CIUDAD LINEAL|      5|\n",
      "|          VICALVARO|      5|\n",
      "|SAN BLAS-CANILLEJAS|      5|\n",
      "| PUENTE DE VALLECAS|      5|\n",
      "|             CENTRO|      5|\n",
      "|          SALAMANCA|      5|\n",
      "|        CARABANCHEL|      5|\n",
      "|          HORTALEZA|      5|\n",
      "|         ARGANZUELA|      5|\n",
      "|             RETIRO|      5|\n",
      "|          MORATALAZ|      5|\n",
      "|    MONCLOA-ARAVACA|      5|\n",
      "|FUENCARRAL-EL PARDO|      5|\n",
      "|          CHAMARTIN|      5|\n",
      "|            BARAJAS|      5|\n",
      "|             LATINA|      5|\n",
      "|         VILLAVERDE|      5|\n",
      "|           CHAMBERI|      5|\n",
      "+-------------------+-------+\n",
      "only showing top 20 rows\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select DISTINCT DESC_DISTRITO, valor_5 FROM padron_5\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ef7616f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "padron_partitioned: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [COD_DISTRITO: int, DESC_DISTRITO: string ... 10 more fields]\r\n",
       "res32: padron_partitioned.type = [COD_DISTRITO: int, DESC_DISTRITO: string ... 10 more fields]\r\n"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val padron_partitioned = padron_df.repartition($\"COD_DISTRITO\", $\"COD_BARRIO\")\n",
    "padron_partitioned.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1fa8e754",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------+---------+---------+--------+--------+\n",
      "|COD_DISTRITO|COD_BARRIO|TotalESPH|TotalESPM|TotalEXH|TotalEXM|\n",
      "+------------+----------+---------+---------+--------+--------+\n",
      "|13          |2         |13875    |15544    |6732    |6961    |\n",
      "|10          |4         |25000    |29776    |5372    |6257    |\n",
      "|15          |2         |23291    |27325    |5477    |6198    |\n",
      "|11          |4         |15988    |19466    |5356    |6000    |\n",
      "|1           |2         |16693    |16666    |8019    |5718    |\n",
      "|13          |6         |17200    |19472    |5332    |5603    |\n",
      "|17          |1         |17087    |19060    |5031    |5236    |\n",
      "|15          |1         |17715    |21818    |3924    |4783    |\n",
      "|10          |2         |15169    |17728    |4097    |4653    |\n",
      "|11          |5         |12525    |14240    |4230    |4624    |\n",
      "|11          |3         |14487    |16574    |4019    |4395    |\n",
      "|8           |6         |26955    |29190    |3532    |4282    |\n",
      "|1           |5         |12542    |12631    |4017    |4040    |\n",
      "|11          |2         |11651    |14084    |3543    |3990    |\n",
      "|17          |4         |14191    |15636    |3794    |3821    |\n",
      "|6           |1         |10202    |11954    |3118    |3776    |\n",
      "|12          |5         |8507     |10247    |3789    |3767    |\n",
      "|19          |1         |13391    |14509    |3687    |3749    |\n",
      "|16          |6         |28457    |28886    |2839    |3724    |\n",
      "|18          |1         |15648    |17029    |3439    |3661    |\n",
      "+------------+----------+---------+---------+--------+--------+\n",
      "only showing top 20 rows\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "//6.10\n",
    "padron_partitioned.select($\"COD_DISTRITO\", $\"COD_BARRIO\", $\"EspanolesHombres\", $\"EspanolesMujeres\", $\"ExtranjerosHombres\", $\"ExtranjerosMujeres\")\n",
    " .groupBy($\"COD_DISTRITO\", $\"COD_BARRIO\")\n",
    " .agg(sum($\"EspanolesHombres\").alias(\"TotalESPH\"), sum($\"EspanolesMujeres\").alias(\"TotalESPM\"), sum($\"ExtranjerosHombres\").alias(\"TotalEXH\"), sum($\"ExtranjerosMujeres\").alias(\"TotalEXM\"))\n",
    " .orderBy($\"TotalEXM\".desc, $\"TotalEXH\".desc)\n",
    " .show(false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b37f3780",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res37: padron_partitioned.type = [COD_DISTRITO: int, DESC_DISTRITO: string ... 10 more fields]\r\n"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//Eliminar de cache\n",
    "padron_partitioned.unpersist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "27df55ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "padron_totalEspH: org.apache.spark.sql.DataFrame = [dis: string, bar: string ... 1 more field]\r\n",
       "padron_join: org.apache.spark.sql.DataFrame = [COD_DISTRITO: int, DESC_DISTRITO: string ... 13 more fields]\r\n"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val padron_totalEspH = padron_df.select($\"DESC_DISTRITO\".alias(\"dis\"), $\"DESC_BARRIO\".alias(\"bar\"), $\"EspanolesHombres\")\n",
    " .groupBy($\"dis\", $\"bar\")\n",
    " .agg(sum($\"EspanolesHombres\").alias(\"Total\"))\n",
    "\n",
    "val padron_join = padron_df.join(padron_totalEspH.as(\"EspH\"), $\"EspH.dis\" === $\"DESC_DISTRITO\" && $\"EspH.bar\" === $\"DESC_BARRIO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "b3841dbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-----------------+-----+\n",
      "|      DESC_DISTRITO|      DESC_BARRIO|Total|\n",
      "+-------------------+-----------------+-----+\n",
      "|FUENCARRAL-EL PARDO|       MIRASIERRA|16011|\n",
      "|          SALAMANCA|       CASTELLANA| 6140|\n",
      "|SAN BLAS-CANILLEJAS|      EL SALVADOR| 4870|\n",
      "|          HORTALEZA|     VALDEFUENTES|28457|\n",
      "|    MONCLOA-ARAVACA|    CASA DE CAMPO| 5421|\n",
      "|          MORATALAZ|       MARROQUINA|11426|\n",
      "|             TETUAN|    BELLAS VISTAS|10202|\n",
      "|          VICALVARO|     EL CA?AVERAL| 2819|\n",
      "|             CENTRO|         JUSTICIA| 7097|\n",
      "|             CENTRO|      UNIVERSIDAD|12542|\n",
      "|      CIUDAD LINEAL|          ATALAYA|  600|\n",
      "|             TETUAN|       BERRUGUETE| 8677|\n",
      "|          VICALVARO|CASCO H.VICALVARO|13391|\n",
      "|          CHAMARTIN|         CASTILLA| 7187|\n",
      "|         ARGANZUELA|          LEGAZPI| 8861|\n",
      "|SAN BLAS-CANILLEJAS|           HELLIN| 3609|\n",
      "|          CHAMARTIN|   HISPANOAMERICA|13254|\n",
      "|  VILLA DE VALLECAS|    SANTA EUGENIA|10375|\n",
      "|             CENTRO|      EMBAJADORES|16693|\n",
      "|         VILLAVERDE|      LOS ANGELES|12449|\n",
      "+-------------------+-----------------+-----+\n",
      "only showing top 20 rows\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "padron_join.select($\"DESC_DISTRITO\", $\"DESC_BARRIO\", $\"Total\").distinct.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "bf7c3a93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.expressions.Window\r\n",
       "padron_totalEspH: org.apache.spark.sql.DataFrame = [COD_DISTRITO: int, DESC_DISTRITO: string ... 11 more fields]\r\n"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.expressions.Window\n",
    "val padron_totalEspH = padron_df\n",
    " .withColumn(\"Total\", sum($\"EspanolesHombres\").over(Window.partitionBy($\"DESC_DISTRITO\", $\"DESC_BARRIO\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "9bc25096",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-----------------+-----+\n",
      "|      DESC_DISTRITO|      DESC_BARRIO|Total|\n",
      "+-------------------+-----------------+-----+\n",
      "|FUENCARRAL-EL PARDO|       MIRASIERRA|16011|\n",
      "|          SALAMANCA|       CASTELLANA| 6140|\n",
      "|SAN BLAS-CANILLEJAS|      EL SALVADOR| 4870|\n",
      "|          HORTALEZA|     VALDEFUENTES|28457|\n",
      "|    MONCLOA-ARAVACA|    CASA DE CAMPO| 5421|\n",
      "|          MORATALAZ|       MARROQUINA|11426|\n",
      "|             TETUAN|    BELLAS VISTAS|10202|\n",
      "|          VICALVARO|     EL CA?AVERAL| 2819|\n",
      "|             CENTRO|         JUSTICIA| 7097|\n",
      "|             CENTRO|      UNIVERSIDAD|12542|\n",
      "|      CIUDAD LINEAL|          ATALAYA|  600|\n",
      "|             TETUAN|       BERRUGUETE| 8677|\n",
      "|          VICALVARO|CASCO H.VICALVARO|13391|\n",
      "|          CHAMARTIN|         CASTILLA| 7187|\n",
      "|         ARGANZUELA|          LEGAZPI| 8861|\n",
      "|SAN BLAS-CANILLEJAS|           HELLIN| 3609|\n",
      "|          CHAMARTIN|   HISPANOAMERICA|13254|\n",
      "|  VILLA DE VALLECAS|    SANTA EUGENIA|10375|\n",
      "|             CENTRO|      EMBAJADORES|16693|\n",
      "|         VILLAVERDE|      LOS ANGELES|12449|\n",
      "+-------------------+-----------------+-----+\n",
      "only showing top 20 rows\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "padron_totalEspH.select(\"DESC_DISTRITO\", \"DESC_BARRIO\", \"Total\").distinct.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c7912e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- COD_DISTRITO: integer (nullable = true)\n",
      " |-- DESC_DISTRITO: string (nullable = true)\n",
      " |-- COD_DIST_BARRIO: integer (nullable = true)\n",
      " |-- DESC_BARRIO: string (nullable = true)\n",
      " |-- COD_BARRIO: integer (nullable = true)\n",
      " |-- COD_DIST_SECCION: integer (nullable = true)\n",
      " |-- COD_SECCION: integer (nullable = true)\n",
      " |-- COD_EDAD_INT: integer (nullable = true)\n",
      " |-- EspanolesHombres: integer (nullable = true)\n",
      " |-- EspanolesMujeres: integer (nullable = true)\n",
      " |-- ExtranjerosHombres: integer (nullable = true)\n",
      " |-- ExtranjerosMujeres: integer (nullable = true)\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "padron_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "67e3e0e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-------+------+------+\n",
      "|COD_EDAD_INT|BARAJAS|CENTRO|RETIRO|\n",
      "+------------+-------+------+------+\n",
      "|           0|    157|   245|   283|\n",
      "|           1|    196|   243|   368|\n",
      "|           2|    179|   241|   382|\n",
      "|           3|    231|   232|   399|\n",
      "|           4|    235|   246|   416|\n",
      "|           5|    275|   232|   390|\n",
      "|           6|    236|   262|   474|\n",
      "|           7|    256|   227|   420|\n",
      "|           8|    244|   257|   421|\n",
      "|           9|    276|   254|   457|\n",
      "|          10|    254|   255|   409|\n",
      "|          11|    256|   253|   403|\n",
      "|          12|    278|   283|   448|\n",
      "|          13|    269|   247|   420|\n",
      "|          14|    265|   249|   424|\n",
      "|          15|    284|   279|   408|\n",
      "|          16|    256|   241|   416|\n",
      "|          17|    247|   274|   451|\n",
      "|          18|    249|   288|   385|\n",
      "|          19|    208|   254|   450|\n",
      "+------------+-------+------+------+\n",
      "only showing top 20 rows\n",
      "\r\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "distritos: Seq[String] = List(BARAJAS, CENTRO, RETIRO)\r\n",
       "padron_pivot: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [COD_EDAD_INT: int, BARAJAS: bigint ... 2 more fields]\r\n"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val distritos = Seq(\"BARAJAS\", \"CENTRO\", \"RETIRO\")\n",
    "val padron_pivot = padron_df.groupBy($\"COD_EDAD_INT\")\n",
    " .pivot($\"DESC_DISTRITO\", distritos)\n",
    " .agg(sum($\"EspanolesMujeres\"))\n",
    " .orderBy($\"COD_EDAD_INT\")\n",
    "\n",
    "padron_pivot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "773a04e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-------+------+------+--------------------+--------------------+--------------------+\n",
      "|COD_EDAD_INT|BARAJAS|CENTRO|RETIRO|          PERBARAJAS|           PERCENTRO|           PERRETIRO|\n",
      "+------------+-------+------+------+--------------------+--------------------+--------------------+\n",
      "|           0|    157|   245|   283|0.006771035494026825|0.003004209720627...|0.002677033778368885|\n",
      "|           1|    196|   243|   368|0.008453012463880622|0.003750478377344049|0.003342029430320...|\n",
      "|           2|    179|   241|   382|0.007719843015482...|0.003425181783390739|0.003052159530751...|\n",
      "|           3|    231|   232|   399|0.009962478975287877|0.004420206659012...|0.003938820400020461|\n",
      "|           4|    235|   246|   416| 0.01013498943373442|0.004496747034060467|0.004007025082271898|\n",
      "|           5|    275|   232|   390|0.011860094018199853|0.005262150784538845|0.004689071904786264|\n",
      "|           6|    236|   262|   474|0.010178117048346057|0.004515882127822426|0.004024076252834757|\n",
      "|           7|    256|   227|   420|0.011040669340578773|0.004898584003061615| 0.00436509966409194|\n",
      "|           8|    244|   257|   421|0.010523137965239142|0.004668962877918...| 0.00416048561733763|\n",
      "|           9|    276|   254|   457| 0.01190322163281149|0.005281285878300804|0.004706123075349122|\n",
      "|          10|    254|   255|   409|  0.0109544141113555|0.004860313815537696|0.004330997322966222|\n",
      "|          11|    256|   253|   403|0.011040669340578773|0.004898584003061615| 0.00436509966409194|\n",
      "|          12|    278|   283|   448| 0.01198947686203476|0.005319556065824723|0.004740225416474841|\n",
      "|          13|    269|   247|   420|0.011601328330530038|0.005147340221967087|0.004586764881409109|\n",
      "|          14|    265|   249|   424|0.011428817872083495| 0.00507079984691925|0.004518560199157673|\n",
      "|          15|    284|   279|   408|0.012248242549704576|0.005434366628396479|0.004842532439851996|\n",
      "|          16|    256|   241|   416|0.011040669340578773|0.004898584003061615| 0.00436509966409194|\n",
      "|          17|    247|   274|   451| 0.01065252080907405| 0.00472636815920398|0.004211639129026208|\n",
      "|          18|    249|   288|   385|0.010738776038297322|0.004764638346727899|0.004245741470151926|\n",
      "|          19|    208|   254|   450|0.008970543839220253|0.003980099502487562|0.003546643477074...|\n",
      "+------------+-------+------+------+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\r\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.expressions.Window\r\n"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.expressions.Window\n",
    "\n",
    "padron_pivot\n",
    " .withColumn(\"PERBARAJAS\", $\"BARAJAS\"/(sum($\"BARAJAS\").over(Window.partitionBy())))\n",
    " .withColumn(\"PERCENTRO\", $\"BARAJAS\"/(sum($\"CENTRO\").over(Window.partitionBy())))\n",
    " .withColumn(\"PERRETIRO\", $\"BARAJAS\"/(sum($\"RETIRO\").over(Window.partitionBy())))\n",
    " .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "80192da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "padron_df.repartition($\"COD_DISTRITO\", $\"COD_BARRIO\").write.format(\"csv\").option(\"encoding\", \"UTF-8\").save(\"Csv/padron.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1d2d51af",
   "metadata": {},
   "outputs": [],
   "source": [
    "padron_df.repartition($\"COD_DISTRITO\", $\"COD_BARRIO\").write.format(\"parquet\").option(\"encoding\", \"UTF-8\").save(\"Parquet/padron.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "dd2d6d98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res28: org.apache.spark.sql.DataFrame = []\r\n"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"create database datos_padron\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "be0e6095",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res31: org.apache.spark.sql.DataFrame = []\r\n"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"use datos_padron\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1138f380",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.SparkConf\r\n",
       "import org.apache.spark.SparkContext\r\n",
       "import org.apache.spark.sql.SparkSession\r\n"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.SparkConf\n",
    "import org.apache.spark.SparkContext\n",
    "import org.apache.spark.sql.SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ee3ed3c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "conf: org.apache.spark.SparkConf = org.apache.spark.SparkConf@6c37f14a\r\n",
       "spark2: org.apache.spark.sql.SparkSession = org.apache.spark.sql.SparkSession@2bf1345d\r\n"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val conf = new SparkConf()\n",
    "      .set(\"spark.sql.catalogImplementation\",\"hive\")\n",
    "      .setMaster(\"local[*]\")\n",
    "      .setAppName(\"Hive Example\")\n",
    "\n",
    "val spark2 = SparkSession.builder()\n",
    "      .config(conf)\n",
    "      .enableHiveSupport()\n",
    "      .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1ca18f25",
   "metadata": {},
   "outputs": [
    {
     "ename": "org.apache.spark.sql.AnalysisException",
     "evalue": " Hive support is required to CREATE Hive TABLE (AS SELECT);\r",
     "output_type": "error",
     "traceback": [
      "org.apache.spark.sql.AnalysisException: Hive support is required to CREATE Hive TABLE (AS SELECT);\r",
      "'CreateTable `datos_padron`.`padron_txt`, org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, ErrorIfExists\r",
      "\r",
      "  at org.apache.spark.sql.execution.datasources.HiveOnlyCheck$.$anonfun$apply$4(rules.scala:462)\r",
      "  at org.apache.spark.sql.execution.datasources.HiveOnlyCheck$.$anonfun$apply$4$adapted(rules.scala:460)\r",
      "  at org.apache.spark.sql.catalyst.trees.TreeNode.foreach(TreeNode.scala:173)\r",
      "  at org.apache.spark.sql.execution.datasources.HiveOnlyCheck$.apply(rules.scala:460)\r",
      "  at org.apache.spark.sql.execution.datasources.HiveOnlyCheck$.apply(rules.scala:458)\r",
      "  at org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis$46(CheckAnalysis.scala:699)\r",
      "  at org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis$46$adapted(CheckAnalysis.scala:699)\r",
      "  at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\r",
      "  at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\r",
      "  at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\r",
      "  at org.apache.spark.sql.catalyst.analysis.CheckAnalysis.checkAnalysis(CheckAnalysis.scala:699)\r",
      "  at org.apache.spark.sql.catalyst.analysis.CheckAnalysis.checkAnalysis$(CheckAnalysis.scala:90)\r",
      "  at org.apache.spark.sql.catalyst.analysis.Analyzer.checkAnalysis(Analyzer.scala:155)\r",
      "  at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:176)\r",
      "  at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:228)\r",
      "  at org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:173)\r",
      "  at org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:73)\r",
      "  at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:111)\r",
      "  at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:143)\r",
      "  at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:772)\r",
      "  at org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:143)\r",
      "  at org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:73)\r",
      "  at org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:71)\r",
      "  at org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:63)\r",
      "  at org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:98)\r",
      "  at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:772)\r",
      "  at org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\r",
      "  at org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:615)\r",
      "  at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:772)\r",
      "  at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:610)\r",
      "  ... 39 elided\r",
      ""
     ]
    }
   ],
   "source": [
    "spark2.sql(\"\"\"create table padron_txt(\n",
    "COD_DISTRITO string,\n",
    "DESC_DISTRITO string,\n",
    "COD_DIST_BARRIO string,\n",
    "DESC_BARRIO string,\n",
    "COD_BARRIO string,\n",
    "COD_DIST_SECCION string,\n",
    "COD_SECCION string,\n",
    "COD_EDAD_INT string,\n",
    "EspanolesHombres string,\n",
    "EspanolesMujeres string,\n",
    "ExtranjerosHombres string,\n",
    "ExtranjerosMujeres string)\n",
    "ROW FORMAT DELIMITED\n",
    "FIELDS TERMINATED BY '\\;'\n",
    "STORED AS TEXTFILE;\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

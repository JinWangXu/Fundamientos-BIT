{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3d01e43162b64c90ce0048e8a23f3b1b",
     "grade": false,
     "grade_id": "cell-f8987996be9f1238",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Accidentes de tráfico en Reino Unido entre 2010 y 2014 \n",
    "\n",
    "### Disponible en Kaggle en:\n",
    "https://www.kaggle.com/stefanoleone992/adm-project-road-accidents-in-uk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9a6b4dc108ddf890c659e33701965428",
     "grade": false,
     "grade_id": "cell-f74d7bfd01811789",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Variables y significado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4a5a5882319ae0a14393c8d534816a56",
     "grade": false,
     "grade_id": "cell-9cfb34982bd4eb04",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "* Accident_Index: Accident index\n",
    "* Latitude: Accident latitude\n",
    "* Longitude: Accident longitude\n",
    "* Region: Accident region\n",
    "* Urban_or_Rural_Area: Accident area (rural or urban)\n",
    "* X1st_Road_Class: Accident road class\n",
    "* Driver_IMD_Decile: Road IMD Decile\n",
    "* Speed_limit: Road speed limit\n",
    "* Road_Type: Road type\n",
    "* Road_Surface_Conditions: Road surface condition\n",
    "* Weather: Weather\n",
    "* High_Wind: High wind\n",
    "* Lights: Road lights\n",
    "* Datetime: Accident datetime\n",
    "* Year: Accident year\n",
    "* Season: Accident season\n",
    "* Month_of_Year: Accident month\n",
    "* Day_of_Month: Accident day of month\n",
    "* Day_of_Week: Accident day of week\n",
    "* Hour_of_Day: Accident hour of day\n",
    "* Number_of_Vehicles: Accident number of vehicles\n",
    "* Age_of_Driver: Driver age\n",
    "* Age_of_Vehicle: Vehicle age\n",
    "* Junction_Detail: Accident junction detail\n",
    "* Junction_Location: Accident junction location\n",
    "* X1st_Point_of_Impact: Vehicle first point of impact\n",
    "* Driver_Journey_Purpose: Driver journey purpose\n",
    "* Engine_CC: Vehicle engine power (in CC)\n",
    "* Propulsion_Code: Vehicle propulsion code\n",
    "* Vehicle_Make: Vehicle brand\n",
    "* Vehicle_Category: Vehicle brand category\n",
    "* Vehicle_Manoeuvre: Vehicle manoeuvre when accident happened\n",
    "* Accident_Severity: Accident severity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nombre completo del alumno:**  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "28429bd5e3051f643a72b2e5787231f5",
     "grade": false,
     "grade_id": "cell-b4f9c37a2b92d2e6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**INSTRUCCIONES**: en cada celda debes responder a la pregunta formulada, asegurándote de que el resultado queda guardado en la(s) variable(s) que por defecto vienen inicializadas a `None`. No se necesita usar variables intermedias, pero puedes hacerlo siempre que el resultado final del cálculo quede guardado exactamente en la variable que venía inicializada a None (debes reemplazar None por la secuencia de transformaciones necesarias, pero nunca cambiar el nombre de esa variable). **No olvides borrar la línea *raise NotImplementedError()* de cada celda cuando hayas completado la solución de esa celda y quieras probarla**.\n",
    "\n",
    "Después de cada celda evaluable verás una celda con código. Ejecútala (no modifiques su código) y te dirá si tu solución es correcta o no. Además de esas pruebas, se realizarán algunas más (ocultas) a la hora de puntuar el ejercicio, pero evaluar dicha celda es un indicador bastante fiable acerca de si realmente has implementado la solución correcta o no. Asegúrate de que, al menos, todas las celdas indican que el código es correcto antes de enviar el notebook terminado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e7764e6064699f591cd2896d2430528e",
     "grade": false,
     "grade_id": "cell-69ec0993eeaff3ac",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Sobre el dataset anterior (accidents_uk.csv) se pide:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **(1 punto)** Leerlo tratando de que Spark infiera el tipo de dato de cada columna, y cachearlo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "494ea1492132b3a5e88d7b7b5ea9c9ce",
     "grade": false,
     "grade_id": "read_csv",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Accident_Index: string, Latitude: double, Longitude: double, Region: string, Urban_or_Rural_Area: string, X1st_Road_Class: string, Driver_IMD_Decile: int, Speed_limit: int, Road_Type: string, Road_Surface_Conditions: string, Weather: string, High_Wind: string, Lights: string, Datetime: string, Year: int, Season: int, Month_of_Year: int, Day_of_Month: int, Day_of_Week: int, Hour_of_Day: double, Number_of_Vehicles: int, Age_of_Driver: int, Age_of_Vehicle: int, Junction_Detail: string, Junction_Location: string, X1st_Point_of_Impact: string, Driver_Journey_Purpose: string, Engine_CC: int, Propulsion_Code: string, Vehicle_Make: string, Vehicle_Category: string, Vehicle_Manoeuvre: string, Accident_Severity: string]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LÍNEA EVALUABLE, NO RENOMBRAR LAS VARIABLES\n",
    "accidentesDF = spark.read\\\n",
    "                .format(\"csv\")\\\n",
    "                .option(\"header\", \"true\")\\\n",
    "                .option(\"inferSchema\", \"true\")\\\n",
    "                .load(\"accidents_uk.csv\")\n",
    "\n",
    "accidentesDF.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fe7160ffc743634220394f78cbf50bc1",
     "grade": true,
     "grade_id": "read_csv_test",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import DoubleType\n",
    "assert(accidentesDF.schema[1].dataType == DoubleType())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1295004c825ce57f3f88b725f083e586",
     "grade": false,
     "grade_id": "cell-b90f5b934eda250e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "* **(1 punto)** Discretizar la variable **Age_of_Vehicle** utilizando un bucketizer (sin crear un pipeline) en los puntos de corte (0, 2, 5, 10, 15, 20, 35). La discretización debe quedar en una nueva columna de tipo Double llamada **Edad_Vehiculo**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bucketizer output with 4 buckets\n",
      "+--------+----------------+\n",
      "|features|bucketedFeatures|\n",
      "+--------+----------------+\n",
      "|  -999.9|             0.0|\n",
      "|    -0.5|             1.0|\n",
      "|    -0.3|             1.0|\n",
      "|     0.0|             2.0|\n",
      "|     0.2|             2.0|\n",
      "|   999.9|             3.0|\n",
      "+--------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Código de prueba para discretizar datos\n",
    "from pyspark.ml.feature import Bucketizer\n",
    "\n",
    "splits = [-float(\"inf\"), -0.5, 0.0, 0.5, float(\"inf\")]\n",
    "\n",
    "data = [(-999.9,), (-0.5,), (-0.3,), (0.0,), (0.2,), (999.9,)]\n",
    "dataFrame = spark.createDataFrame(data, [\"features\"])\n",
    "\n",
    "bucketizer = Bucketizer(splits=splits, inputCol=\"features\", outputCol=\"bucketedFeatures\")\n",
    "\n",
    "# Transform original data into its bucket index.\n",
    "bucketedData = bucketizer.transform(dataFrame)\n",
    "\n",
    "print(\"Bucketizer output with %d buckets\" % (len(bucketizer.getSplits())-1))\n",
    "bucketedData.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "467714adc92d47c04b7573bd1f1faa06",
     "grade": false,
     "grade_id": "bucketize",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Bucketizer\n",
    "\n",
    "splits = [-float(\"inf\"), 0, 2, 5, 10, 15, 20, 35, float(\"inf\")]\n",
    "bucketizer = Bucketizer(splits=splits, inputCol=\"Age_of_Vehicle\", outputCol=\"Edad_Vehiculo\")\n",
    "accidentesBucketizedDF = bucketizer.transform(accidentesDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-------------+\n",
      "|Age_of_Vehicle|Edad_Vehiculo|\n",
      "+--------------+-------------+\n",
      "|             8|          3.0|\n",
      "|             3|          2.0|\n",
      "|             8|          3.0|\n",
      "|             2|          2.0|\n",
      "|            12|          4.0|\n",
      "|             2|          2.0|\n",
      "|            11|          4.0|\n",
      "|             5|          3.0|\n",
      "|             1|          1.0|\n",
      "|             4|          2.0|\n",
      "|             8|          3.0|\n",
      "|             2|          2.0|\n",
      "|             4|          2.0|\n",
      "|            10|          4.0|\n",
      "|             8|          3.0|\n",
      "|            14|          4.0|\n",
      "|             8|          3.0|\n",
      "|             4|          2.0|\n",
      "|             8|          3.0|\n",
      "|             7|          3.0|\n",
      "+--------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accidentesBucketizedDF.select(\"Age_of_Vehicle\", \"Edad_Vehiculo\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7c1ac69726ac8effcf1a2124b1e2cd3a",
     "grade": true,
     "grade_id": "bucketize_tests",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert(\"Edad_Vehiculo\" in accidentesBucketizedDF.columns)\n",
    "assert(accidentesBucketizedDF.schema.fields)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "cdd57f341bfabbfbb3c648ec78af5a64",
     "grade": false,
     "grade_id": "cell-fc88821f19453a51",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "* **(1 punto)** Crear un nuevo DF donde la columna \"Age_of_Driver\" ha sido reemplazada por otra de tipo string en la que los valores 1 y 2 son \"Adolescente\", los valores 3 y 4 por \"Joven\", los valores 5 y 6 por \"Adulto\", y los demás valores se dejan sin modificar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c9ee5110f5af1c97a769ec03d3431c3f",
     "grade": false,
     "grade_id": "renombrar_edad",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'accidentesDF' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-bc37a19cf5cc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msql\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtypes\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# LÍNEA EVALUABLE, NO RENOMBRAR VARIABLES\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m age = accidentesDF.withColumn(\"edad\", expr(\"case when Age_of_Driver in (1,2) then 'Adolescente'\" +\n\u001b[0m\u001b[0;32m      5\u001b[0m                                                       \u001b[1;34m\"when Age_of_Driver in (3,4) then 'Joven'\"\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m                                                       \u001b[1;34m\"when Age_of_Driver in (5,6) then 'Adulto'\"\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'accidentesDF' is not defined"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "# LÍNEA EVALUABLE, NO RENOMBRAR VARIABLES\n",
    "age = accidentesDF.withColumn(\"edad\", expr(\"case when Age_of_Driver in (1,2) then 'Adolescente'\" +\n",
    "                                                      \"when Age_of_Driver in (3,4) then 'Joven'\" +\n",
    "                                                      \"when Age_of_Driver in (5,6) then 'Adulto'\" +\n",
    "                                                      \"else Age_of_Driver end\"))\n",
    "age2 = age.drop(\"Age_of_Driver\")\n",
    "\n",
    "accidentesAgeDF = age2.withColumnRenamed(\"edad\", \"Age_of_Driver\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|Age_of_Driver|\n",
      "+-------------+\n",
      "|        Joven|\n",
      "|        Joven|\n",
      "|            7|\n",
      "|        Joven|\n",
      "|       Adulto|\n",
      "|       Adulto|\n",
      "|       Adulto|\n",
      "|        Joven|\n",
      "|        Joven|\n",
      "|        Joven|\n",
      "|  Adolescente|\n",
      "|        Joven|\n",
      "|        Joven|\n",
      "|       Adulto|\n",
      "|        Joven|\n",
      "|       Adulto|\n",
      "|        Joven|\n",
      "|        Joven|\n",
      "|        Joven|\n",
      "|        Joven|\n",
      "+-------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "root\n",
      " |-- Accident_Index: string (nullable = true)\n",
      " |-- Latitude: double (nullable = true)\n",
      " |-- Longitude: double (nullable = true)\n",
      " |-- Region: string (nullable = true)\n",
      " |-- Urban_or_Rural_Area: string (nullable = true)\n",
      " |-- X1st_Road_Class: string (nullable = true)\n",
      " |-- Driver_IMD_Decile: integer (nullable = true)\n",
      " |-- Speed_limit: integer (nullable = true)\n",
      " |-- Road_Type: string (nullable = true)\n",
      " |-- Road_Surface_Conditions: string (nullable = true)\n",
      " |-- Weather: string (nullable = true)\n",
      " |-- High_Wind: string (nullable = true)\n",
      " |-- Lights: string (nullable = true)\n",
      " |-- Datetime: string (nullable = true)\n",
      " |-- Year: integer (nullable = true)\n",
      " |-- Season: integer (nullable = true)\n",
      " |-- Month_of_Year: integer (nullable = true)\n",
      " |-- Day_of_Month: integer (nullable = true)\n",
      " |-- Day_of_Week: integer (nullable = true)\n",
      " |-- Hour_of_Day: double (nullable = true)\n",
      " |-- Number_of_Vehicles: integer (nullable = true)\n",
      " |-- Age_of_Vehicle: integer (nullable = true)\n",
      " |-- Junction_Detail: string (nullable = true)\n",
      " |-- Junction_Location: string (nullable = true)\n",
      " |-- X1st_Point_of_Impact: string (nullable = true)\n",
      " |-- Driver_Journey_Purpose: string (nullable = true)\n",
      " |-- Engine_CC: integer (nullable = true)\n",
      " |-- Propulsion_Code: string (nullable = true)\n",
      " |-- Vehicle_Make: string (nullable = true)\n",
      " |-- Vehicle_Category: string (nullable = true)\n",
      " |-- Vehicle_Manoeuvre: string (nullable = true)\n",
      " |-- Accident_Severity: string (nullable = true)\n",
      " |-- Age_of_Driver: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accidentesAgeDF.select(\"Age_of_Driver\").show()\n",
    "accidentesAgeDF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4f33a56b8af18220e6b77664c0f11851",
     "grade": true,
     "grade_id": "renombrar_edad_test",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Row(Age_of_Driver='8', count=9195), Row(Age_of_Driver='7', count=13338), Row(Age_of_Driver='Adolescente', count=57174), Row(Age_of_Driver='Adulto', count=67138), Row(Age_of_Driver='Joven', count=104987)]\n"
     ]
    }
   ],
   "source": [
    "assert(dict(accidentesAgeDF.dtypes)[\"Age_of_Driver\"] == \"string\")\n",
    "collectedDF = accidentesAgeDF.groupBy(\"Age_of_Driver\").count().orderBy(\"count\").collect()\n",
    "print(collectedDF)\n",
    "assert((collectedDF[0][\"count\"] == 9195) & (collectedDF[0][\"Age_of_Driver\"] == \"8\"))\n",
    "assert((collectedDF[1][\"count\"] == 13338) & (collectedDF[1][\"Age_of_Driver\"] == \"7\"))\n",
    "assert((collectedDF[2][\"count\"] == 57174) & (collectedDF[2][\"Age_of_Driver\"] == \"Adolescente\"))\n",
    "assert((collectedDF[3][\"count\"] == 67138) & (collectedDF[3][\"Age_of_Driver\"] == \"Adulto\"))\n",
    "assert((collectedDF[4][\"count\"] == 104987) & (collectedDF[4][\"Age_of_Driver\"] == \"Joven\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b805abfe5774032f7cf030b50153b2a8",
     "grade": false,
     "grade_id": "cell-a71a6b17b1e0d613",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "* **(1 punto)** Partiendo de `accidentesDF`, crear un nuevo DataFrame de una sola fila que contenga, **por este orden de columnas**, el **número** de categorías existentes para el propósito del viaje, para el tipo de maniobra del vehículo, para las condiciones de la calzada y para la severidad del accidente. Pista: crear las columnas al vuelo con `select`(). Renombrar cada columna de conteo para que se llame igual que la propia columna que estamos contando."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "760ca31245afc350de47c7cd98aa6950",
     "grade": false,
     "grade_id": "numero_categorias",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# LÍNEA EVALUABLE, NO RENOMBRAR VARIABLES\n",
    "numeroCategoriasDF = accidentesDF.select(countDistinct(\"Driver_Journey_Purpose\").alias(\"proposito\"),\n",
    "                                         countDistinct(\"Vehicle_Manoeuvre\").alias(\"maniobra\"),\n",
    "                                        countDistinct(\"Road_Surface_Conditions\").alias(\"condiciones\"),\n",
    "                                        countDistinct(\"Accident_Severity\").alias(\"severidad\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+-----------+---------+\n",
      "|proposito|maniobra|condiciones|severidad|\n",
      "+---------+--------+-----------+---------+\n",
      "|        5|      11|          5|        2|\n",
      "+---------+--------+-----------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "numeroCategoriasDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "30ebc9730a12379f2bcce1ad04f24e33",
     "grade": true,
     "grade_id": "numero_categorias_test",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert(len(numeroCategoriasDF.columns) == 4)\n",
    "assert(numeroCategoriasDF.count() == 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8b42e836688d46b3680b7ab2dc4d3169",
     "grade": false,
     "grade_id": "cell-c5ec05706eccd480",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "* **(3 puntos)** Partiendo de `accidentesAgeDF` definido anteriormente, crear un nuevo DataFrame con tantas filas como posibles propósitos de un viaje, y tantas columnas como rangos de edad habíamos distinguido en dicho DataFrame más una (la del propósito del viaje). Las columnas deben llamarse igual que cada uno de los niveles posibles de rangos de edad. Cada casilla del nuevo DataFrame deberá contener el **porcentaje** del número de accidentes ocurridos en ese tipo de viaje (fila) para ese rango de edad (columna), medido sobre el *total de accidentes ocurridos para ese tipo de viaje*.\n",
    "\n",
    "Pista: se puede hacer todo en una sola secuencia de transformaciones sin variable auxiliar. Calcular primero el conteo, después añadir una columna con los totales de cada tipo de viaje como la suma de las 5 columnas de conteos, y finalmente reemplazar cada columna de conteo por su porcentaje. No debe utilizarse `when` en ningún momento, solo aritmética de columnas. Recuerda cómo desplegar grupos en varias columnas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7098be8996fe3e79691c07ae1552d862",
     "grade": false,
     "grade_id": "viajes_por_edad",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+--------------------+--------------------+-------------------+-------------------+-------------------+\n",
      "|Driver_Journey_Purpose|                   7|                   8|        Adolescente|             Adulto|              Joven|\n",
      "+----------------------+--------------------+--------------------+-------------------+-------------------+-------------------+\n",
      "|  Taking pupil to/f...|0.026578073089700997|0.009060706735125339|0.07550588945937783|0.22259136212624583|   0.66626396858955|\n",
      "|  Pupil riding to/f...|0.021611001964636542| 0.01768172888015717| 0.6227897838899804|0.12573673870333987|0.21218074656188604|\n",
      "|  Journey as part o...|0.023330770595540836|0.003814536637293749|0.15536105032822758|0.31802590336507186|  0.499467739073866|\n",
      "|       Other/Not known| 0.06503169065192967| 0.04814613718101034|0.24026836256901252| 0.2565088137105748|0.39004499588747266|\n",
      "|  Commuting to/from...|0.012527948326649396|0.002519785640770...|  0.236327501153423| 0.2791993469851297|0.46942541789402703|\n",
      "+----------------------+--------------------+--------------------+-------------------+-------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "total = accidentesAgeDF.select(\"Driver_Journey_Purpose\").groupBy(\"Driver_Journey_Purpose\").agg(count(\"*\").alias(\"Total\"))\n",
    "pivot = accidentesAgeDF.select(\"Driver_Journey_Purpose\", \"Age_Of_Driver\").groupBy(\"Driver_Journey_Purpose\").pivot(\"Age_Of_Driver\").agg(count(\"*\"))\n",
    "joined = pivot.join(total, \"Driver_Journey_Purpose\", 'inner')\n",
    "viajesPorEdadDF = joined.select(\"Driver_Journey_Purpose\",\n",
    "           (col(\"7\")/col(\"Total\")).alias(\"7\"),\n",
    "           (col(\"8\")/col(\"Total\")).alias(\"8\"),\n",
    "           (col(\"Adolescente\")/col(\"Total\")).alias(\"Adolescente\"),\n",
    "           (col(\"Adulto\")/col(\"Total\")).alias(\"Adulto\"),\n",
    "           (col(\"Joven\")/col(\"Total\")).alias(\"Joven\"))\n",
    "viajesPorEdadDF.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1e85aec10339652ee69e69997a220ba1",
     "grade": true,
     "grade_id": "viajes_por_edad_test",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Invalid argument, not a string or column: 0.0 of type <class 'float'>. For column literals, use 'lit', 'array', 'struct' or 'create_map' function.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-118-e31ee61bdc52>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mcommuting\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mviajesPorEdadDF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0morderBy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Driver_Journey_Purpose\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32massert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommuting\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDriver_Journey_Purpose\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Commuting\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[1;32massert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommuting\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'7'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m0.012527948326649396\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0.001\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;32massert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommuting\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'8'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m0.002519785640770\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0.001\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32massert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommuting\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAdolescente\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m0.236327501153423\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0.001\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\spark\\spark-3.1.1-bin-hadoop2.7\\python\\pyspark\\sql\\functions.py\u001b[0m in \u001b[0;36mabs\u001b[1;34m(col)\u001b[0m\n\u001b[0;32m    150\u001b[0m     \u001b[0mComputes\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mabsolute\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    151\u001b[0m     \"\"\"\n\u001b[1;32m--> 152\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_invoke_function_over_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"abs\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\spark\\spark-3.1.1-bin-hadoop2.7\\python\\pyspark\\sql\\functions.py\u001b[0m in \u001b[0;36m_invoke_function_over_column\u001b[1;34m(name, col)\u001b[0m\n\u001b[0;32m     64\u001b[0m     \u001b[1;32mand\u001b[0m \u001b[0mwraps\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;32mclass\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m~\u001b[0m\u001b[0mpyspark\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msql\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mColumn\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m     \"\"\"\n\u001b[1;32m---> 66\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_invoke_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_to_java_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\spark\\spark-3.1.1-bin-hadoop2.7\\python\\pyspark\\sql\\column.py\u001b[0m in \u001b[0;36m_to_java_column\u001b[1;34m(col)\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[0mjcol\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_create_column_from_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m         raise TypeError(\n\u001b[0m\u001b[0;32m     46\u001b[0m             \u001b[1;34m\"Invalid argument, not a string or column: \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m             \u001b[1;34m\"{0} of type {1}. \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Invalid argument, not a string or column: 0.0 of type <class 'float'>. For column literals, use 'lit', 'array', 'struct' or 'create_map' function."
     ]
    }
   ],
   "source": [
    "assert(len(viajesPorEdadDF.columns) >= 6)\n",
    "assert(\"7\" in viajesPorEdadDF.columns)\n",
    "assert(\"8\" in viajesPorEdadDF.columns)\n",
    "assert(\"Adolescente\" in viajesPorEdadDF.columns)\n",
    "assert(\"Joven\" in viajesPorEdadDF.columns)\n",
    "assert(\"Adulto\" in viajesPorEdadDF.columns)\n",
    "assert(viajesPorEdadDF.columns[0] == \"Driver_Journey_Purpose\")\n",
    "assert(viajesPorEdadDF.count() == 5)\n",
    "commuting = viajesPorEdadDF.orderBy(\"Driver_Journey_Purpose\").collect()[0]\n",
    "assert(commuting.Driver_Journey_Purpose.startswith(\"Commuting\"))\n",
    "assert(abs(commuting['7'] - 0.012527948326649396) < 0.001)\n",
    "assert(abs(commuting['8'] - 0.002519785640770) < 0.001)\n",
    "assert(abs(commuting.Adolescente - 0.236327501153423) < 0.001)\n",
    "assert(abs(commuting.Adulto - 0.2791993469851297) < 0.001)\n",
    "assert(abs(commuting.Joven - 0.46942541789402703) < 0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "49d2b52bb5a2988f54170966f3657b57",
     "grade": false,
     "grade_id": "cell-9ebe35c4b4325269",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "* **(3 puntos)** Unir la información obtenida en el paso anterior al DataFrame `accidentesAgeDF`, de manera que **al resultado final se añada una columna nueva llamada `Porcentaje`** que contenga el porcentaje de accidentes que ha habido para ese rango de edad y ese tipo de viaje de entre todos los viajes que ha habido de ese tipo (es decir, el porcentaje adecuado de la tabla anterior). Por ejemplo, si el accidente se produjo en un trayecto de tipo `Commuting...` y la persona es `Joven`, entonces la columna Porcentaje tomará el valor de la columna `Joven` y por tanto tendrá el valor 0.46942, pero si la persona es `Adulto`, entonces tomará el valor de la columna `Adulto` el cual será 0.2791993469851297.\n",
    "\n",
    "PISTA: unir los dos DF mediante join() convencional, y a continuación, crear la nueva columna `Porcentaje` en el resultado, utilizando `when` para ver cuál es el valor que debe tener en cada fila (más concretamente: de qué columna debemos tomarlo) en función del valor de la columna `Age_of_Driver`. No se necesitan variables intermedias; se puede hacer en una secuencia de transformaciones encadenadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2e8addac1e30ac1f6a2d5fed36ff4010",
     "grade": false,
     "grade_id": "join",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+-------------+--------------------+\n",
      "|Driver_Journey_Purpose|Age_of_Driver|          Porcentaje|\n",
      "+----------------------+-------------+--------------------+\n",
      "|  Taking pupil to/f...|  Adolescente| 0.07550588945937783|\n",
      "|  Taking pupil to/f...|        Joven|    0.66626396858955|\n",
      "|  Taking pupil to/f...|       Adulto| 0.22259136212624583|\n",
      "|  Taking pupil to/f...|       Adulto| 0.22259136212624583|\n",
      "|  Taking pupil to/f...|        Joven|    0.66626396858955|\n",
      "|  Taking pupil to/f...|       Adulto| 0.22259136212624583|\n",
      "|  Taking pupil to/f...|        Joven|    0.66626396858955|\n",
      "|  Taking pupil to/f...|        Joven|    0.66626396858955|\n",
      "|  Taking pupil to/f...|            7|0.026578073089700997|\n",
      "|  Taking pupil to/f...|        Joven|    0.66626396858955|\n",
      "|  Taking pupil to/f...|        Joven|    0.66626396858955|\n",
      "|  Taking pupil to/f...|            7|0.026578073089700997|\n",
      "|  Taking pupil to/f...|        Joven|    0.66626396858955|\n",
      "|  Taking pupil to/f...|            7|0.026578073089700997|\n",
      "|  Taking pupil to/f...|       Adulto| 0.22259136212624583|\n",
      "|  Taking pupil to/f...|        Joven|    0.66626396858955|\n",
      "|  Taking pupil to/f...|       Adulto| 0.22259136212624583|\n",
      "|  Taking pupil to/f...|  Adolescente| 0.07550588945937783|\n",
      "|  Taking pupil to/f...|        Joven|    0.66626396858955|\n",
      "|  Taking pupil to/f...|        Joven|    0.66626396858955|\n",
      "+----------------------+-------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# LÍNEA EVALUABLE, NO RENOMBRAR VARIABLES\n",
    "finalDF = viajesPorEdadDF.join(accidentesAgeDF, \"Driver_Journey_Purpose\").withColumn(\"Porcentaje\", when(col(\"Age_of_Driver\") == \"7\", col(\"7\"))\\\n",
    "                                                                                    .when(col(\"Age_of_Driver\") == \"8\", col(\"8\"))\\\n",
    "                                                                                    .when(col(\"Age_of_Driver\") == \"Adolescente\", col(\"Adolescente\"))\\\n",
    "                                                                                    .when(col(\"Age_of_Driver\") == \"Adulto\", col(\"Adulto\"))\\\n",
    "                                                                                    .when(col(\"Age_of_Driver\") == \"Joven\", col(\"Joven\")))\n",
    "finalDF.select(col(\"Driver_Journey_Purpose\"),col(\"Age_of_Driver\"),col(\"Porcentaje\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "afede5f5bc886534cae92a88870b9688",
     "grade": true,
     "grade_id": "join_tests",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Invalid argument, not a string or column: 0.0 of type <class 'float'>. For column literals, use 'lit', 'array', 'struct' or 'create_map' function.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-130-085a9a6482cd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32massert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Porcentaje\"\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfinalDF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32massert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msum_cond\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfinalDF\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Porcentaje\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Age_of_Driver\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"Adolescente\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m13344.826819125037\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0.001\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;32massert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msum_cond\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfinalDF\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Porcentaje\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Age_of_Driver\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"Joven\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m44438.00809518224\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0.001\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32massert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msum_cond\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfinalDF\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Porcentaje\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Age_of_Driver\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"Adulto\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m18028.24488479408\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0.001\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\spark\\spark-3.1.1-bin-hadoop2.7\\python\\pyspark\\sql\\functions.py\u001b[0m in \u001b[0;36mabs\u001b[1;34m(col)\u001b[0m\n\u001b[0;32m    150\u001b[0m     \u001b[0mComputes\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mabsolute\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    151\u001b[0m     \"\"\"\n\u001b[1;32m--> 152\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_invoke_function_over_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"abs\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\spark\\spark-3.1.1-bin-hadoop2.7\\python\\pyspark\\sql\\functions.py\u001b[0m in \u001b[0;36m_invoke_function_over_column\u001b[1;34m(name, col)\u001b[0m\n\u001b[0;32m     64\u001b[0m     \u001b[1;32mand\u001b[0m \u001b[0mwraps\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;32mclass\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m~\u001b[0m\u001b[0mpyspark\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msql\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mColumn\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m     \"\"\"\n\u001b[1;32m---> 66\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_invoke_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_to_java_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\spark\\spark-3.1.1-bin-hadoop2.7\\python\\pyspark\\sql\\column.py\u001b[0m in \u001b[0;36m_to_java_column\u001b[1;34m(col)\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[0mjcol\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_create_column_from_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m         raise TypeError(\n\u001b[0m\u001b[0;32m     46\u001b[0m             \u001b[1;34m\"Invalid argument, not a string or column: \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m             \u001b[1;34m\"{0} of type {1}. \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Invalid argument, not a string or column: 0.0 of type <class 'float'>. For column literals, use 'lit', 'array', 'struct' or 'create_map' function."
     ]
    }
   ],
   "source": [
    "def sum_cond(df, column, condition): \n",
    "    return(df.where(condition).select(F.sum(column).alias(column)).collect()[0][column])\n",
    "    \n",
    "assert(\"Porcentaje\" in finalDF.columns)\n",
    "assert(abs(sum_cond(finalDF, \"Porcentaje\", F.col(\"Age_of_Driver\") == \"Adolescente\") - 13344.826819125037) < 0.001)\n",
    "assert(abs(sum_cond(finalDF, \"Porcentaje\", F.col(\"Age_of_Driver\") == \"Joven\") - 44438.00809518224) < 0.001)\n",
    "assert(abs(sum_cond(finalDF, \"Porcentaje\", F.col(\"Age_of_Driver\") == \"Adulto\") - 18028.24488479408) < 0.001)\n",
    "assert(abs(sum_cond(finalDF, \"Porcentaje\", F.col(\"Age_of_Driver\") == \"7\") - 812.0952970292334) < 0.001)\n",
    "assert(abs(sum_cond(finalDF, \"Porcentaje\", F.col(\"Age_of_Driver\") == \"8\") - 432.2987413617681) < 0.001)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
